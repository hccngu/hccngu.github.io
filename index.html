---
layout: page
title: Hi, I'm Chengcheng Han
subtitle: Researcher in Large Language Models Evaluation and Analysis.
use-site-title: true
---

<br>I recently completed my PhD at <a href="https://www.ecnu.edu.cn/">East China Normal University (ECNU)</a> in the <a href="http://dase.ecnu.edu.cn/">School of Data Science and Engineering</a>, where I was advised by <a href="http://dase.ecnu.edu.cn/mgao/index.html">Ming Gao</a> and <a href="https://lixiang3776.github.io/">Xiang Li</a>.

My current research interests focus on the evaluation and analysis of large language models.

I have gained substantial industry experience through several internships:

1. In 2021, I interned with the NLP group at Alibaba, gaining insights into industry-level NLP applications.
2. In 2022, I continued my journey with the NLP group at Meituan, further honing my skills.
3. From January to June 2023, I interned at Microsoft Xiaoice, focusing on enhancing the reasoning capabilities of large language models.
4. From June to October 2023, I was at Ant Group, researching techniques to mitigate hallucinations in large language models.
5. From October 2023 to May 2024, I worked at Shanghai AI Lab, concentrating on developing AI Agents for operating systems.
6. Since July 1, 2024, I have been a full-time researcher at Meituan.

I'm currently on the lookout for interns interested in large model evaluation and analysis. If you're ready to dive into this exciting field, shoot me an email at hccngu@163.com. Let's explore the future of AI together!<br><br>

<!--  My bachelor thesis was on deep learning methods
for relation extraction in clinical text, supervised by <a href="http://www.iitg.ac.in/anand.ashish/index.html">Ashish
	Anand</a>.<br><br> -->

When I'm not doing NLP, I like to work out, play guitar, and read.<br>

<hr style="height:2px;border-width:0;color:gray;background-color:gray">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VDSYJWMWJB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VDSYJWMWJB');
</script>

<b>Updates:</b><br><br>

<ul>
	<!-- <li><i>October 2022:</i> I am selected as a recipient for the inaugural JHU+Amazon <a
			href="https://ai2ai.engineering.jhu.edu/2022-2023-ai2ai-fellows/">AI2AI fellowship</a> for 2022-23.
	</li><br>

	<li><i>May 2022:</i> I passed my GBO (JHU CS qualifying exam) and officially became a Ph.D. candidate (<a
			href="./static/ppt/gbo_presentation.pdf">here</a> are
		the slides for my presentation). Also,
		I'll be starting an internship at Meta AI (Menlo Park) in the Speech team.
	</li><br> -->

	<li><i>March 2024:</i> We released a self-improving embodied conversational agent, <a href="https://os-copilot.github.io/">OS-Copilot</a>, seamlessly integrated into the operating system to automate our daily tasks. Friends who are interested can try it out~</li><br>

	<li><i>March 2024:</i> In March, we published a survey paper titled "<a href="https://arxiv.org/pdf/2403.14734.pdf">A Survey of Neural Code Intelligence: Paradigms, Advances, and Beyond</a>". We hope it attracts a lot of interest and attention!</li><br>
	
	<li><i>March 2024:</i> <b>2 papers</b> were accepted at <a href="https://lrec-coling-2024.org/">COLING 2024</a>. Check out the publications page for more info!</li><br>

	<li><i>October 2023:</i> <b>1 papers</b> accepted at <a href="https://2023.emnlp.org/">EMNLP 2023</a>.
		Check out publications page for more info!
	</li><br>

	<li><i>May 2023:</i> We've created an open-source project, <a href="https://github.com/hccngu/Viscacha">Viscacha</a>, aiming to release a comprehensive Chinese information extraction dataset. We welcome everyone to pay close attention to it~
	</li><br>

	<li><i>May 2023:</i> <b>1 papers</b> accepted at <a href="https://2023.aclweb.org/">ACL 2023</a>.
		Check out publications page for more info!
	</li><br>

	<li><i>February 2023:</i> Our team, <b>DataIsPower</b>, won the runner-up prize in the pre-trained language model application tuning algorithm category 
		at <a href="https://iacc.pazhoulab-huangpu.com/lists/149.html">the Guangdong-Hong Kong-Macau Greater Bay Area International Algorithm Competition</a>, 
		with a prize money of Â¥200,000. 
		We are so grateful!!!
	</li><br>

	<li><i>January 2023:</i> <b>1 papers</b> accepted at <a href="http://www.tjudb.cn/dasfaa2023/">DASFAA 2023</a>.
		Check out publications page for more info! Also, I attended DASFAA 2023 in person :)
	</li><br>
		<!-- These papers investigate multi-talker ASR with neural transducers, and adding domain knowledge for
		fine-tuning of large self-supervised models. <a href="./static/pdf/clsp_recruitment_poster.pdf">Here</a> is a
		poster describing both papers. -->
	<!-- </li><br>

	<li><i>Janurary 2022:</i> I participated in the Mini SCALE workshop organized by HLTCOE. I was in the
		<b>"Improving speech analytics for room audio"</b> team led by <a href="https://m-wiesner.github.io/">Matthew
			Wiesner</a>.
	</li><br>

	<li><i>June 2021:</i> <b>4 papers</b> accepted at <a href="https://www.interspeech2021.org/">INTERSPEECH 2021</a>.
		Check out publications page for more info! Also, I am attending ICASSP 2021 virtually :)
	</li><br>

	<li><i>April 2021:</i> Our JHU-GoVivace team placed <b>2nd</b> (and 1st in the Hindi-English task) in the <a
			href="https://navana-tech.github.io/IS21SS-indicASRchallenge/leaderboard.html">Indic code-switching
			challenge</a>.</li><br> -->

</ul>
